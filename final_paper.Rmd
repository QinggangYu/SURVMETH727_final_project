---
title: "Does collectivism modulate sentiment on COVID-19 pandemic?"
subtitle: "An examination of Twitter data in the United States"
author: "Tong Suo & Qinggang Yu"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    df_print: kable
    latex_engine: xelatex
bibliography: mybib.bib
csl: ASA.csl
link-citations: yes
---

```{r, include = FALSE}
library(knitr)
library(tidyverse)
library(foreign)
library(readxl)
library(stargazer)
library(ggrepel)
library(readr)
```

# Introduction



# Data

## Data collection

### Twitter data

The data of the present study were collected by live-streaming tweets during a three-week period from October 30th to November 19th. We targeted this period because it overlapped with the onset of the "third wave" of the COVID-19 pandemic in the U.S., when about ??? new cases and ??? new deaths happened. We conducted two separate lines of collection. One collection streamed tweets containing words that are related to the COVID-19 pandemic, such as "covid", "corona", and "pandemic" (see the supplementary materials for a full list of the keywords). The other collection streamed general tweets, which means we did not limit the collection to any specific keywords. Both collection streamed tweets generated from within the U.S. by applying a bounding box defined by geographical coordinates.  
The COVID-related tweets were collected in Python using the tweepy package, which provides wrapper functions of the Twitter API. On each day, the collection starts from between 10am and 12pm and runs for 10 hours. Due to technical issues, the collection did not run properly for two days within the three-week period, so we collected an additional day of day on November 20th. A brief demonstration of the Python codes used for the data collection is as follows. The complete version of the codes is included in the supplementary materials.


```{python, eval = FALSE, python.reticulate = FALSE}
all_tweets = []
box = [-178.334698, 18.910360999999998, -66.949895, 49.384358]
#The listener, MyStreamListener, is customized to collect only COVID-related tweets
#and append the tweets to the container
myStream = tweepy.Stream(auth = api.auth, listener = MyStreamListener(36000), 
                         tweet_mode = 'extended')
myStream.filter(locations = box)
```

The general tweets were collected in R using the rtweet package. On each day, the collection starts from ...
A brief demonstration of the R codes used for the data collection is as follows.

```{r, eval = FALSE}
# R code for collection
```

### State-level collectivism

The level of collectivism for each continental states of the U.S. (plus Hawaii) was retrieved from a previous study. The score ranges from 0 (least collectivistic) to 100 (most collectivistic). The collectivism score was calculated from eight demographic/social indicators of each state. Some sample indicators of collectivism include percentage of people living alone (reverse-coded), percentage of self-employed workers (reverse-coded), divorce to marriage ratio (reverse-coded), and percentage of households with grandchildren in them. Because the collectivism score for Hawaii is exceedingly high, due to a bunch of sociocultural reasons, we winsorized it to 3 standard deviations above the mean.

### Covariates

We included a few state-level covariates in our model. Some of them are demographic, such as population, median age, median household income, and the level of conservatism. These data were retrieved from the U.S. Census Bureau. We additionally include the number of new cases and the number of new deaths of COVID-19 for each state during our three-week data collection period, as the sentiment might covary with the progression of the pandemic. The COVID-19 data were retrieved from a public database maintained by the John Hopkins website.

## Data cleaning

We first mapped the collected tweets to the state they were originated. This was accomplished using the reverse-geocode package in Python for the covid-related tweets. The coordinate bounding box of each tweet, embedded in the tweet json object of each corresponding tweet, was first extracted and its midpoint was identified. The package then output the state where the midpoint coordinate falls in. Along this process, we also dropped tweets originating from outside the U.S. but were incidentially collected (because of the imperfect overlap between the bounding box and the U.S. territory), and tweets in other languages than English. A brief demonstration of the Python codes used for this process (for covid-related tweets) is as follows.

```{python, eval = FALSE, python.reticulate = FALSE}
def sort_data(dates):
    f_name = dates + '_covid.pkl'
    infile = open(f_name, "rb")
    curr_day = pickle.load(infile)
    infile.close()
    all_states = {}
    #coords is a panda dataframe containing the name and coordinates of each state
    for i in range(coords.shape[0]):
        place = coords.loc[i, "NAME"]
        all_states[place] = []
    for twt in curr_day:
        if hasattr(twt, "place") and hasattr(twt.place, "country_code") \
        and hasattr(twt.place, "bounding_box"):
            if (twt.place.country_code == "US") and (twt.lang == "en"):
                loc_box = twt.place.bounding_box.coordinates[0]
                loc = np.mean(loc_box, axis = 0)
                coordinates = (loc[1], loc[0])
                r = rg.search(coordinates)
                place = r[0]['admin1']
                all_states[place].append(twt)
    outname = 'bystate_' + f_name
    f = open(outname, "wb")
    pickle.dump(all_states, f)
    f.close()
    return all_states
    
dates = ['1030', '1031', '1102', '1103', '1105', '1106', '1107', '1108', 
          '1109', '1110', '1111', '1112', '1113', '1114', '1115', '1116',
          '1117', '1118', '1119', '1120']
for day in dates:
    all_states = sort_data(day)
    #further processing starts here
    #See code chunk under sentiment analysis
```

The corresponding R codes for the geo-mapping procedure of the general tweets are illustrated below. Note that we did an additional cleaning process for the general tweets. Our data collection period overlapped with another extremely emotion-laden events in the U.S., which is the presidential election. Therefore, we dropped tweets containing words related broadly to politics, the election, and the candidates in order to prevent any emotional bias due to the election from contaminating our baseline sentiment estimates. Towards this end, we dropped tweets containing keywords such as :????? 

```{r}
#R code for geo-mapping
```

## Sentiment analysis

We performed sentiment analysis with two widely-used models: VADER and NRC Word-Emotion Association Lexicon. VADER stands for Valence Aware Dictionary and Sentiment Reasoner, and it is a lexicon and rule-based model that quantifies a given text in terms of its positivity or negativity. We adopted three scores output by VADER for each tweet: Compound score, which is the general sentiment that varies from -1 (most negative) to +1 (most positive); Positivity score, which is the ratio of positive words to the whole text, thus varies from 0 to 1; and Negativity score, which is the ratio of negative words to the whole text, thus varies from 0 to 1 as well.  
NRC Word-Emotion Association Lexicon (called NRC hereafter) is also a lexicon-based model that quantifies the emotion assoicated with a given text. The NRC include a list of words and the eight emotion categories they belong to: anger, fear, anticipation, trust, surprise, sadness, joy, and disgust (note that NRC also links words to the two sentiments, positive and negative, but we did not use them since those were already quantified in VADER). Therefore, for a given text, NRC outputs the number of words belonging to each emotion category. We adopted these eight scores of each tweet in the present study to examine the more specific emotions of the tweets as a funciton of collectivism.  
The python codes used to calculate the sentiment/emotion of the covid-related tweets are listed below:

```{python, eval = FALSE, python.reticulate = FALSE}
for day in dates:
    all_states = sort_data(day)
    #container for vader scores
    vader_state = {}
    for i in all_states.keys():
        vader_state[i] = {'pos':[], 'neg':[], 'neu':[], 'compound':[]}
    #container for NRC scores
    NRC_state = {}
    for i in all_states.keys():
        NRC_state[i] = {'fear': [], 'anger': [], 'anticipation': [], \
                       'trust': [], 'surprise': [], 'positive': [], \
                       'negative': [], 'sadness': [], 'disgust': [], 'joy': [], \
                       'length': [], 'sentence': []}
    #looping through the data                   
    for s in all_states.keys():
        curr_states = all_states[s]
        if len(curr_states) > 0:
            #fetch the text of each tweet
            for i in range(len(curr_states)):
                tweet = curr_states[i]
                if hasattr(tweet, "extended_tweet"):
                    text = tweet.extended_tweet["full_text"]
                else:
                    text = tweet.text
                #Vader analysis
                broken_sent = nltk.sent_tokenize(text)
                sent_scores = {'pos':[], 'neg':[], 'neu':[], 'compound':[]}
                for sentence in broken_sent:
                    vs = analyzer.polarity_scores(sentence)
                    for k in vs.keys():
                        sent_scores[k].append(vs[k])
                for k in sent_scores.keys():
                    text_score = sum(sent_scores[k])/len(sent_scores[k])
                    vader_state[s][k].append(text_score)
                #NRC analysis
                text_object = NRCLex(text)
                text_score = text_object.affect_count
                text_length = len(text_object.words)
                NRC_state[s]['length'].append(text_length)
                NRC_state[s]['sentence'].append(len(text_object.sentences))
                for k in text_score.keys():
                    NRC_state[s][k].append(text_score[k])
```

The corresponding R codes for the general tweets are presented below:

```{r}
#R code for sentiment analysis
```

## Statistial analysis

We used multiple regression analysis to predict the sentiment of each state using the state-level collectivism, after controlling for the relevant covariates. We first analyzed sentiment based on VADER. We aggregated the score (compound score, as well as the positivity and negativity score) of all the covid-related tweets of each state across the days of the data collection period. We repeated the same procedure for the general tweets. Hence, we obtained one compound score, one positivity score, and one negativity score for each state on covid-related tweets, and likewise on general tweets. We first fit a base model, using only collectivism to predict the sentiment scores. We next fit a model including all the covariates. All the predictors were z scored. Each regression was weighted by the number of tweets collected for each state, since greater number provides a more reliable estimate of the sentiment. The R codes for VADER analysis are included below:  

```{r read_RDS, echo = F, warning=F, message=F}
general_url <- "https://github.com/QinggangYu/SURVMETH727_final_project/raw/main/COVID_WaveIII_s9_stccount.rds"
download.file(general_url, "general_t.rds")
general_t <- readRDS('general_t.rds')
```

```{r VADER_processing, warning=F, message=F, results='asis'}
##COVID TWEETS
cov_url <- "https://raw.githubusercontent.com/QinggangYu/SURVMETH727_final_project/main/Predictors_US_states.csv"
cov <- read_csv(url(cov_url))
covid_t_url <- "https://raw.githubusercontent.com/QinggangYu/SURVMETH727_final_project/main/vader_sentiment.csv"
covid_t <- read_csv(url(covid_t_url))
cd_url <- "https://raw.githubusercontent.com/QinggangYu/SURVMETH727_final_project/main/covid_21day_covariates.csv"
case_death <- read_csv(url(cd_url))

covid_t_agg <- covid_t %>% 
  group_by(state) %>% 
  summarise_at(vars(compound:count), mean, na.rm = TRUE)

comb_data <- cov %>% 
  left_join(covid_t_agg, by = c("State" = "state"))

full_data <- comb_data %>% 
  left_join(case_death, by = c("State" = "state"))

full_data <- subset(full_data, !is.na(full_data$compound))

full_data[, c(3:23, 25:26)] <- lapply(full_data[, c(3:23, 25:26)], scale)
full_data[full_data$State == "Hawaii", "Collectivism"] <- 3


#COMPOUND SCORE

#base model(With weight)
b_model_w <- lm(compound ~ Collectivism, weights = count, data = full_data)

#with covariates (with weight)
cov_model_w <- lm(compound ~ Collectivism + Population + Income + Median_age + 
                    Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data)

#Pos SCORE

#base model(With weight)
b_modelpos_w <- lm(pos ~ Collectivism, weights = count, data = full_data)

#with covariates (with weight)
cov_modelpos_w <- lm(pos ~ Collectivism + Population + Income + Median_age + 
                       Conservatism + case_sum + death_sum, 
                     weights = count, data = full_data)

#Neg SCORE

#base model(With weight)
b_modelneg_w <- lm(neg ~ Collectivism, weights = count, data = full_data)

#with covariates (with weight)
cov_modelneg_w <- lm(neg ~ Collectivism + Population + Income + Median_age + 
                       Conservatism + case_sum + death_sum,
                     weights = count, data = full_data)

##GENERAL TWEETS

general_t_agg <- general_t %>%
  #filter(politics == FALSE) %>%
  #filter(covid == TRUE) %>% 
  group_by(state) %>%
  summarise(
    compound = mean(vader_compound, na.rm = TRUE),
    pos = mean(vader_pos, na.rm = TRUE),
    neg = mean(vader_neg, na.rm = TRUE),
    count = n()
  )
    

comb_data_gen <- cov %>% 
  left_join(general_t_agg, by = c("State" = "state"))

full_data_gen <- comb_data_gen %>% 
  left_join(case_death, by = c("State" = "state"))

full_data_gen <- subset(full_data_gen, !is.na(full_data_gen$compound))

full_data_gen[, c(3:22, 24, 25)] <- lapply(full_data_gen[, c(3:22, 24, 25)], scale)

##COMPOUND SCORE

#base model(With weight)
b_gen_w <- lm(compound ~ Collectivism, weights = count, data = full_data_gen)

#with covariates (with weight)
cov_gen_w <- lm(compound ~ Collectivism + Population + Income + Median_age+ 
                  Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data_gen)

##Pos SCORE

#base model(With weight)
b_genpos_w <- lm(pos ~ Collectivism, weights = count, data = full_data_gen)

#with covariates (with weight)
cov_genpos_w <- lm(pos ~ Collectivism + Population + Income + Median_age + 
                     Conservatism + case_sum + death_sum, 
                     weights = count, data = full_data_gen)

##Neg SCORE

#base model(With weight)
b_genneg_w <- lm(neg ~ Collectivism, weights = count, data = full_data_gen)

#with covariates (with weight)
cov_genneg_w <- lm(neg ~ Collectivism + Population + Income + Median_age + 
                     Conservatism + case_sum + death_sum, 
                     weights = count, data = full_data_gen)
```

We performed the same set of analyses for sentiment scores from NRC. Because there are eight specific emotions, and we did not have a priori predictions on which emotions were likely involved, we treated our analyses as exploratory. We fit the base model and the model with covariates on each emotion score, for both the covid-related tweets and general tweets. In addition to the covariates we included in VADER analysis, we also controlled for the averaged number of sentences in the NRC analysis. This is because NRC produced raw count of occurrence of the words belonging to each emotion category, thus longer text will have a higher number of the count. Because there are eight emotion categories, we corrected for multiple correction using the Bonferroni method, and set the threshold of significance to *p* < 0.00625 (0.5/8). The R codes for NRC analysis are included below:

```{r NRC_processing, warning=F, message=F}

NRC_url <- "https://raw.githubusercontent.com/QinggangYu/SURVMETH727_final_project/main/NRC_raw.csv"
covid_t <- read_csv(url(NRC_url))

covid_t_agg <- covid_t %>% 
  group_by(state) %>% 
  summarise_at(vars(fear:num_sentence), mean, na.rm = TRUE)

comb_data <- covid_t_agg %>% 
  left_join(case_death, by = "state")

full_data_NRC <- cov %>% 
  left_join(comb_data, by = c("State" = "state"))
full_data_NRC[, c(3:29, 31:34)] <- lapply(full_data_NRC[, c(3:29, 31:34)], scale)

#iterated fitting
varlist <- names(full_data_NRC)[c(20:24, 27:29)]
models <- lapply(varlist, function(x){
  lm(substitute(i ~ Collectivism + Population + Income + Median_age + Conservatism + 
                  num_sentence + case_sum + death_sum, list(i = as.name(x))), 
     weights = count, data = full_data_NRC)
})

general_t_agg <- general_t %>%
  #filter(politics == FALSE) %>% 
  group_by(state) %>%
  summarise_at(vars(anger:trust, sentence_count_1), mean, na.rm = TRUE)

general_t_count <- general_t %>%
  #filter(politics == FALSE) %>% 
  group_by(state) %>%
  summarise(count = n())

general_t_data <- left_join(general_t_agg, general_t_count, by = "state")
    

comb_data_gen <- general_t_data %>% 
  left_join(case_death, by = "state")

full_data_genNRC <- cov %>% 
  left_join(comb_data_gen, by = c("State" = "state"))

full_data_genNRC[, c(3:28, 30:31)] <- lapply(full_data_genNRC[, c(3:28, 30:31)], scale)

models_gen <- lapply(varlist, function(x){
  lm(substitute(i ~ Collectivism + Population + Income + Median_age + Conservatism + 
                  sentence_count_1 + case_sum + death_sum, 
                list(i = as.name(x))), weights = count, data = full_data_genNRC)
})
```

# Results

## VADER analysis

We found that when more collectivist states tweeted about COVID-19, the sentiment of the tweets tended to be more positive (Fig. 1). This was evident in both the base model (*b* = `r b_model_w$coefficients[2]`, *p* = `r summary(b_model_w)$coefficients[2,4]`), as well as after controlling for the covariates (*b* = `r cov_model_w$coefficients[2]`, *p* = `r summary(cov_model_w)$coefficients[2,4]`). The positivity of the sentiment likely arose from their tweets containing more positive words, although this was only statisitically significant in the base model (*b* = `r b_modelpos_w$coefficients[2]`, *p* = `r summary(b_modelpos_w)$coefficients[2,4]`). Collectivism did not have any effects on the negativity score of the covid-related tweets, either in the base model or after controlling the covariates , *p*s > .05. These effects are summarized in Table 1.

```{r Table1, echo=FALSE, warning=F, message=F, results='asis'}
stargazer(b_model_w, cov_model_w, b_modelpos_w, cov_modelpos_w, b_modelneg_w, cov_modelneg_w,
          title = "Vader Sentiment on Covid-related tweets", dep.var.labels = c("Compound Score", "Positivity Score", "Negativity Score"),
          covariate.labels = c("Collectivism", "Population", "Income", "Median age", "Conservatism", "case number", "death number"),
          column.sep.width = "1pt",
          omit.stat = c("ll", "aic", "bic", "f", "ser"))
```

```{r echo = F, warning=F, message=F}
plot_m <- lm(compound ~ Population + Income + Median_age + Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data)

plot_m2 <- lm(Collectivism ~ Population + Income + Median_age + Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data)

full_data$Compound_adjusted <- plot_m$residuals
full_data$Collectivism_adjusted <- plot_m2$residuals

ggplot(data = full_data, mapping = aes(x = Collectivism_adjusted, y = Compound_adjusted)) + 
  geom_point(aes(size = count)) + 
  geom_smooth(method = "lm") +
  geom_text_repel(aes(label = State),
                  label.padding = 0.25,
                  size = 2.5,
                  segment.size = 0.15,
                  segment.alpha = 1) +
  labs(x = "Adjusted Collectivism", y = "Adjusted Compound Score", size = "Number of tweets per day", 
       title = "Fig. 1. Collectivism predicts more positive sentiment in Covid-related tweets") +
  theme(legend.title = element_text(size = 8))
```

We observed a very different picture for the general tweets. In particular, the sentiment of the general tweets from more collectivist states are more negative (Fig. 2). This was evident in both the base model (*b* = `r b_gen_w$coefficients[2]`, *p* = `r summary(b_gen_w)$coefficients[2,4]`), as well as after controlling for the covariates (*b* = `r cov_gen_w$coefficients[2]`, *p* = `r summary(cov_gen_w)$coefficients[2,4]`). This negative sentiment was driven by tweets in collectivist states containing more negative words (*b* = `r cov_genneg_w$coefficients[2]`, *p* = `r summary(cov_genneg_w)$coefficients[2,4]`), as well as less positive words (*b* = `r cov_genpos_w$coefficients[2]`, *p* = `r summary(cov_genpos_w)$coefficients[2,4]`). This result was consistent before or after controlling the covariates (stats above depicting models including the covariates. These effects are summarized in Table 2.

```{r Table2, echo=FALSE, warning=F, message=F, results='asis'}
stargazer(b_gen_w, cov_gen_w, b_genpos_w, cov_genpos_w, b_genneg_w, cov_genneg_w,
          title = "Vader Sentiment on General tweets", dep.var.labels = c("Compound Score", "Positivity Score", "Negativity Score"),
          covariate.labels = c("Collectivism", "Population", "Income", "Median age", "Conservatism", "case number", "death number"),
          column.sep.width = "1pt",
          omit.stat = c("ll", "aic", "bic", "f", "ser"))
```

```{r echo = F, warning=F, message=F}
plot_m <- lm(compound ~ Population + Income + Median_age + Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data_gen)

plot_m2 <- lm(Collectivism ~ Population + Income + Median_age + Conservatism + case_sum + death_sum, 
                  weights = count, data = full_data_gen)

full_data_gen$Compound_adjusted <- plot_m$residuals
full_data_gen$Collectivism_adjusted <- plot_m2$residuals

ggplot(data = full_data_gen, mapping = aes(x = Collectivism_adjusted, y = Compound_adjusted)) + 
  geom_point(aes(size = count)) + 
  geom_smooth(method = "lm") +
  geom_text_repel(aes(label = State),
                  label.padding = 0.25,
                  size = 2.5,
                  segment.size = 0.15,
                  segment.alpha = 1) +
  labs(x = "Adjusted Collectivism", y = "Adjusted Compound Score", size = "Number of tweets per day", 
       title = "Fig. 2. Collectivism predicts more negative sentiment in general tweets") +
  theme(legend.title = element_text(size = 8)) + 
  scale_size(range = c(0, 2))
```

## NRC analysis

The results for the effect of collectivism on specific emotions in covid-related tweets are illustrated in Fig. 3 (note that we plotted the 95% confidence interval of the estimate, hence the uncorrected estimate). Although there seems to be a few notable effects, only the effect on fear and trust survived the correction for multiple-comparison. Covid-related Tweets in more collectivist states tended to contain less sentiment of fear and trust.

```{r echo = F, warning=F, message=F}
coef_table <- data.frame(matrix(ncol = 3, nrow = 0))

for (i in 1:length(models)){
  m <- models[[i]]
  conf_int <- confint(m, "Collectivism")
  row <- c(m$coefficients[2], conf_int[1], conf_int[2])
  coef_table <- rbind(coef_table, row)
}
names(coef_table) = c("Coefficient", "lower", "upper")

coef_table$emotion <- varlist

ggplot(data = coef_table) +
  geom_linerange(aes(xmin = lower, xmax = upper, y = emotion, color = emotion)) + 
  geom_point(aes(x = Coefficient, y = emotion)) + 
  geom_vline(aes(xintercept = 0)) +
  labs(x = "Effect of Collectivism", y = "Emotion",
       title = "Fig. 3. Effect of collectivism on different emotions of covid-related tweets") +
  theme(legend.position = "none")
```

The results for the effect of collectivism on specific emotions in general tweets are illustrated in Fig. 3 (note that we plotted the 95% confidence interval of the estimate, hence the uncorrected estimate). Again, the effect of collectivism on a few emotions was notable in the uncorrected results. However, none of the effects survived the correction for multiple-comparison.

```{r echo = F, warning=F, message=F}
coef_table_gen <- data.frame(matrix(ncol = 3, nrow = 0))

for (i in 1:length(models_gen)){
  m <- models_gen[[i]]
  conf_int <- confint(m, "Collectivism")
  row <- c(m$coefficients[2], conf_int[1], conf_int[2])
  coef_table_gen <- rbind(coef_table_gen, row)
}
names(coef_table_gen) = c("Coefficient", "lower", "upper")

coef_table_gen$emotion <- varlist

ggplot(data = coef_table_gen) +
  geom_linerange(aes(xmin = lower, xmax = upper, y = emotion, color = emotion)) + 
  geom_point(aes(x = Coefficient, y = emotion)) + 
  geom_vline(aes(xintercept = 0)) +
  labs(x = "Effect of Collectivism", y = "Emotion",
       title = "Fig. 4. Effect of collectivism on different emotions of general tweets") +
  theme(legend.position = "none")
```


# Discussion

This section summarizes the results and may briefly outline advantages and limitations of the work presented.

# References

# Supplementary materials
